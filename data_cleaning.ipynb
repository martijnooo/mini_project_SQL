{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all countries\n",
    "countries_short = [country.alpha_2 for country in pycountry.countries]\n",
    "countries_name = [country.name for country in pycountry.countries]\n",
    "\n",
    "countries_df = pd.DataFrame({'handle': countries_short, 'name': countries_name}).reset_index()\n",
    "countries_df = countries_df.rename(columns={\"index\":\"country_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       8807 non-null   object\n",
      " 1   type          8807 non-null   object\n",
      " 2   title         8807 non-null   object\n",
      " 3   director      6173 non-null   object\n",
      " 4   cast          7982 non-null   object\n",
      " 5   country       7976 non-null   object\n",
      " 6   date_added    8797 non-null   object\n",
      " 7   release_year  8807 non-null   int64 \n",
      " 8   rating        8803 non-null   object\n",
      " 9   duration      8804 non-null   object\n",
      " 10  listed_in     8807 non-null   object\n",
      " 11  description   8807 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 825.8+ KB\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\netflix_titles_anandshaw.csv\")\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
       "       'release_year', 'rating', 'duration', 'listed_in', 'description',\n",
       "       'ufo_theme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows with including the words \"alien\" and \"ufo\" in the title or description? \n",
    "filtered_df = movies[movies['title'].str.contains('alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', case=False, na=False) | \n",
    "                     movies['description'].str.contains('alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', case=False, na=False)]\n",
    "print(len(filtered_df))\n",
    "\n",
    "# create new column that indicates if movie has ufo theme\n",
    "movies['ufo_theme'] = np.where(\n",
    "    movies['description'].str.contains(\n",
    "        'alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', \n",
    "        case=False, \n",
    "        na=False\n",
    "    ), \n",
    "    'yes', \n",
    "    'no'\n",
    ")\n",
    "\n",
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['date_added'] = pd.to_datetime(movies['date_added'], errors='coerce')\n",
    "# Drop rows where 'date_added' is NaT due to coercion errors\n",
    "movies = movies.dropna(subset=['date_added'])\n",
    "movies = movies[['date_added', 'ufo_theme', 'release_year', 'type', 'title']]\n",
    "movies['date_added_formatted'] = movies['date_added'].dt.strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO reports cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_report  = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\nuforc_reports (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143940 entries, 0 to 143939\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Date_Table  143940 non-null  object\n",
      " 1   Date        143940 non-null  object\n",
      " 2   Posted      143940 non-null  object\n",
      " 3   City        143933 non-null  object\n",
      " 4   State       143895 non-null  object\n",
      " 5   Country     143938 non-null  object\n",
      " 6   Shape       143940 non-null  object\n",
      " 7   Duration    143915 non-null  object\n",
      " 8   Image       143940 non-null  object\n",
      " 9   Link        143940 non-null  object\n",
      " 10  Summary     143940 non-null  object\n",
      " 11  Text        143906 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ufo_report.info()\n",
    "\n",
    "# rename columns to lower case\n",
    "ufo_report.columns = ufo_report.columns.str.lower()\n",
    "\n",
    "# remove columns 'Date', 'Posted', 'Shape', 'Duration', 'Image', 'Link', 'Summary', 'Text' (to avoid confusion about correct date column and other columns)\n",
    "ufo_report = ufo_report.drop(columns=['date','posted', 'shape', 'duration', 'image', 'link', 'summary', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date                city    state  country\n",
      "0                         04/2023            Honolulu       HI      USA\n",
      "1                         04/2023         Bakersfield  Unknown      USA\n",
      "2                         04/2023         Castle Dale  Unknown  Unknown\n",
      "3                         04/2023           Baltimore       MD      USA\n",
      "4                         03/2023             Madison       WI      USA\n",
      "...                           ...                 ...      ...      ...\n",
      "143935                    07/1947             Roswell       NM      USA\n",
      "143936                    06/1947      Corpus Christi       TX      USA\n",
      "143937                    06/1952              Auburn       WA      USA\n",
      "143938  UNSPECIFIED / APPROXIMATE           Troutdale       OR      USA\n",
      "143939                    06/1950  Budapest (Hungary)  Unknown  Hungary\n",
      "\n",
      "[143940 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# rename column date_table\n",
    "ufo_report = ufo_report.rename(columns={'date_table': 'date'})\n",
    "print(ufo_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid rows: 376\n",
      "           date                city    state  country\n",
      "0       04/2023            Honolulu       HI      USA\n",
      "1       04/2023         Bakersfield  Unknown      USA\n",
      "2       04/2023         Castle Dale  Unknown  Unknown\n",
      "3       04/2023           Baltimore       MD      USA\n",
      "4       03/2023             Madison       WI      USA\n",
      "...         ...                 ...      ...      ...\n",
      "143934  07/1954             Oakdale       NY      USA\n",
      "143935  07/1947             Roswell       NM      USA\n",
      "143936  06/1947      Corpus Christi       TX      USA\n",
      "143937  06/1952              Auburn       WA      USA\n",
      "143939  06/1950  Budapest (Hungary)  Unknown  Hungary\n",
      "\n",
      "[143564 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "correct_format = r'^\\d{1,2}/\\d{4}$'\n",
    "\n",
    "# count rows that do not have date format of MM/YYYY in 'Date_Table'\n",
    "invalid_rows_count = ufo_report[~ufo_report['date'].str.match(correct_format, na=False)].shape[0]\n",
    "\n",
    "print(f\"invalid rows: {invalid_rows_count}\")\n",
    "\n",
    "# remove rows with invalid date format \n",
    "ufo_report = ufo_report[ufo_report['date'].str.match(correct_format, na=False)]\n",
    "print(ufo_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'Unknown' 'United Kingdom' 'Canada' 'turkey' 'India' 'Australia'\n",
      " 'Malta' 'Switzerland' 'France' 'Guam' 'Puerto Rico' 'Ukraine' 'Mexico'\n",
      " 'Ireland' 'Japan' 'Germany' 'Poland' 'New Zealand' 'Pakistan'\n",
      " 'South Africa' 'Papua New Guinea' 'Kenya' 'Thailand' 'Israel' 'Denmark'\n",
      " 'Malaysia' 'Lebanon (Middle East)' 'Argentina' 'Myanmar' 'Cambodia'\n",
      " 'Croatia' 'On the way to Cozumel' 'South-Africa' 'Brazil' 'Macedonia'\n",
      " 'Cyprus' 'China' 'Panama' 'Romania' 'In Orbit' 'Trinidad/Tobago'\n",
      " 'Jamaica' 'Luxemburg' 'Italy' 'East China Sea' 'Bulgaria' 'Iran' 'Spain'\n",
      " 'Decalb' 'Portugal' 'Turkey' 'Indonesia' 'Lebanon' 'South Korea'\n",
      " 'North Wales' 'Belgium' 'Netherlands' 'Luxembourg' 'Philippines'\n",
      " 'Guatemala' 'Srui Lanka' 'Jordan' 'Afghanistan' 'Finland' 'Taiwan'\n",
      " 'Algeria' 'Venezuela' 'Bahamas'\n",
      " 'South Georgia and the south sandwich islands' 'Costa Rica' 'Honduras'\n",
      " 'Lithuania' 'Bahrain' 'Palau' 'Western Australia' 'Mozambique'\n",
      " 'Dominican Republic' 'Belize' 'Slovenia' 'Bosnia and Herzegovina'\n",
      " 'Colombia' 'Greece' 'Hellenic Republic' 'Hungary' 'Latvia' 'Sweden'\n",
      " 'Portereco  2 miles of the coast' 'Republic of Ireland'\n",
      " 'Republic of South Africa' 'Peru' 'Tenerife, Spain' 'Armenia' 'Mauritius'\n",
      " 'Egypt' 'Nigeria' 'Mars' 'Caribbean Sea' 'Djibouti' 'Norway' 'Fiji'\n",
      " 'Puerto rico' 'Iraq' 'Scotland' 'Bangladesh' 'Czech Republic' 'Serbia'\n",
      " 'Zimbabwe' 'Bolivia' 'Russia (former Ukraine)'\n",
      " 'Isle of Man, Great Britain' 'South Korea / Japan' 'Viet Nam' 'canada'\n",
      " 'OMAN/UAE' 'Isle of Man' 'Nicaragua' 'Brunei' 'italy' 'Chile'\n",
      " 'Caicos Islands' 'Quebec' 'United States\\r\\n\\r\\n\\r\\n'\n",
      " 'Grand Canary Island' 'London' 'Grenada' 'St Thomas and Nassau'\n",
      " 'Over ocean between London and Northern Netherlands' 'Zambia' 'Georgia'\n",
      " 'U. S. Virgin Islands' 'Austria' 'Dominica, West Indies' 'Nigeria 🇳🇬'\n",
      " 'Qatar' 'Sri Lanka' 'Northern Ireland' 'Russia'\n",
      " 'Puerto Rico Commonwealth' 'Hong Kong S.A.R.' 'hatton city, Sri Lanka'\n",
      " 'Bermuda' 'non applicable' 'Kosovo' 'Ecuador' 'Russian Federation'\n",
      " 'Regatul Unit' 'United Arab Emirates' 'Menorca' 'Curacao'\n",
      " 'British Virgin Islands' 'Cuba' 'Tunisia' 'Azerbaijan' 'Albania'\n",
      " 'Estonia' 'Trinidad and Tobago' 'Botswana' 'Slovakia' 'Sukumwit'\n",
      " 'Caribbean (Grand Turk)' 'South  Africa' 'US and Canada Border' 'Morocco'\n",
      " 'Saudi Arabia' 'Kuwait' 'US Virgin Islands' 'Nepal'\n",
      " 'Israel\\\\occupied palestine' 'Maldives' 'Iceland' 'Saipan' 'Barbados'\n",
      " 'Kazakhstan' 'American Samoa' 'Santo Domingo' 'usa' 'Roma'\n",
      " 'Chennai. Tamil Nadu' 'india' 'Liberia' 'Tanzania'\n",
      " 'Turks and Caicos Islands' 'Bosnia and herzegovina' 'Tenerife' 'USAUSA'\n",
      " 'Dublin Ireland' 'No' 'Grenoble' 'Italy/Greece' 'mexico' 'Singapore'\n",
      " 'Hong Kong SAR' 'UK/England' 'Nederland' 'Mongolia' 'Republic of Panama'\n",
      " 'Macedonia (FYROM)' 'south africa' 'Citizen' 'Namibia' 'Murcia'\n",
      " 'In orbit' 'South Atlantic/Caribbean (on cruise ship)' 'Atlantic Ocean'\n",
      " 'The Bahamas' 'Antigua' 'none' 'Senegal' 'Slovak Republic'\n",
      " 'United Arad Emirates' 'Norge' 'Martinique' 'St. Kitts' 'Syria' 'Moon'\n",
      " 'Korea (South)' 'Trinidad' 'Cuba/Florida (between)'\n",
      " 'Netherlands Antilles' 'In orbit (space)' 'Seychelles'\n",
      " 'Sultanate of Oman' 'united kingdom' 'Hong Kong' 'Serbia and Montenegro'\n",
      " 'Yup' 'Mediterranean sea.' 'Bahamas The' 'Tijuana b.c' 'Antarctica'\n",
      " 'USAv' 'UAE' 'Paraguay' 'Ghana' 'Yes' 'Aruba' 'Vietnam' 'U.S.A.'\n",
      " 'Reunion Island' 'Corsica (France)' 'El Salvador' 'North Atlantic'\n",
      " 'Andaman Islands' 'Nauru' 'Perú' 'Virgin Islands' 'Korea South' 'Angola'\n",
      " 'Gambia' 'Grand Cayman' 'Thailand & Malaysia' 'Kyrgyzistan'\n",
      " 'French West Indies' 'Uruguay' 'Republic of Macedonia'\n",
      " 'In orbit in space' 'Ethiopia'\n",
      " 'Pacific Ocean ( between Philippines and Japan )' 'Mediterranean Sea'\n",
      " 'Bahamas/USA' 'Grenadine Islands' 'Saint Helena South Atlantic Ocean'\n",
      " 'Greenland' 'Gulf of Mexico / Florida straits' 'El Cobre' 'Suriname'\n",
      " 'Indian Ocean' 'mid-Atlantic Ocean' 'Gran Canaria' 'Yugoslavia'\n",
      " 'Crete (Greece)' 'Oakland' 'Corsica' 'ITALY' 'Aegean Sea'\n",
      " 'Indian Ocean 500 miles from nearest land' 'USVI' 'Trinidad & Tobago'\n",
      " 'Okinawa' 'Europe' 'Untied States of America' 'Chad' 'Yemen' 'Usa'\n",
      " 'Sweden/Denmark' 'Persian Gulf' 'Congo' 'Space via nasa tv'\n",
      " 'East Atlantic Ocean' 'Swizterland' 'Uzbekistan' 'Pacific Ocean'\n",
      " 'France/Antibes' 'U' 'China Also?' 'yes' 'Gibraltar' 'Saint Maarten'\n",
      " 'Northern Cyprus' 'Korea' 'Haiti' 'St. Lucia' 'Tokyo to Honolulu'\n",
      " 'Türkiye' 'Democratic Republic of the Congo' 'Mid-Atlantic Ocean'\n",
      " 'United kingdom' 'Nairobi' 'slovakia' 'Palestine' 'Lesotho' 'East Timor'\n",
      " 'Netherlands The' 'Virgin Islands (U.S.)' 'Monaco' 'Sri lanka' 'Tasmania'\n",
      " 'Gulf of Mexico' 'Republic of Georgia' 'Cameroon' 'Kosova'\n",
      " 'Republic of Korea' 'Colorado springs' 'Federated States of Micronesia'\n",
      " 'SriLanka' 'Czech republic' 'over New Brunswick' 'Lake Ontario'\n",
      " 'Pacific Ocean (in-fight)' 'sri lanka' 'Guinea' nan 'Surinam'\n",
      " 'Myanmar (Burma)' 'Cayman Islands' 'Faroe Islands' 'SI' 'Sinai'\n",
      " 'International Space Station' 'Switzerland/UK (in flight)' 'Anguilla'\n",
      " 'UK/Wales' 'Guyana, South America' 'finland' 'Channel Islands'\n",
      " 'Above the pacific ocean' 'Guatamala' 'United States' 'Puerto Rico usa'\n",
      " 'French Polynesia' 'great britain' 'USA/Canadian Waters' 'Ochorios'\n",
      " 'San Juan and St. Thomas USVI' 'Japan (Okinawa)' 'West Germany'\n",
      " 'Caribbean Sea/Atantic Ocean' 'Uganda' 'Virgin Islands (U. S.)'\n",
      " 'New Zealand -Taranaki' 'Germany/Holland' 'North Atlantic Ocean'\n",
      " 'Turks & Caicos' 'Guyana' 'Malawi' 'Kingdom of Bahrain'\n",
      " 'Panama Canal Zone' 'Euleuthera' 'Nekoosa'\n",
      " 'Puerto Rico/Burmuda (between)' 'North Sea' 'Kenya (East Africa)'\n",
      " 'Montenegro' 'PUERTO RICO' 'Foreign' 'Vanuatu' 'Okinawa Japan'\n",
      " 'Croatia (Hrvatska)' 'Caribbean' 'United States Minor Outlying Islands'\n",
      " 'San Miguel Tecuitlapa, Puebla, Mexico' 'Outer Mongolia' 'Burkina Faso'\n",
      " 'Atlantic Ocean/Puerto Rico' 'Libya' 'Germany (West Germany)'\n",
      " 'St. Helena Island' 'Grand Cayman Island' 'Virgin Islands (US)' 'Tonga'\n",
      " 'St. Martin' 'Tyrrhenian Sea' 'Israel - near Petach Tikva'\n",
      " 'Rhodesia (Now Zimbabwe)' 'Solomon Islands' 'Moldova (Republic of )'\n",
      " 'India (south- east)' 'Somalia' 'Slovakia/Austria' 'Belarus'\n",
      " 'Pacific Ocean (western)' 'South Atlantic Ocean' 'CZECH republic'\n",
      " 'Republic of Palau' 'Dubai' 'Saint Kitts And Nevis' 'france'\n",
      " 'St. Maarten/Netherland Antilles' 'Swaziland' 'Mauritius Island' 'Laos'\n",
      " 'Tuvalu' 'Middle of the Atlantic Ocean' 'Oman'\n",
      " 'lat 2 deg 48 min N  124 deg W' 'Near Earth Orbit' 'Panama Canal'\n",
      " 'Turkmenistan' 'Dominican republic' 'saipan' 'Tunisia-ITALIA,MIDELLSEA'\n",
      " 'Kazakstan' 'Netherland Antilles' 'Saint Lucia' 'St. Thomas'\n",
      " 'Cruise ship' 'Fiji Islands' 'Cape Verde Island' 'Germany/France'\n",
      " 'South Pacific' 'USA & Canada' 'South Pacific Ocean' 'Central Viet Nam'\n",
      " 'Russia (USSR)' 'Azores' 'Far East' 'Midway Island' 'mediterranean sea'\n",
      " 'Philippine Sea' 'South Vietnam' 'no' 'unknown/at sea'\n",
      " 'Mediterrainian Sea' 'Orust']\n"
     ]
    }
   ],
   "source": [
    "# based on unique values from country we clean country column and remove invalid values\n",
    "unique_countries = ufo_report['country'].unique()\n",
    "print(unique_countries)\n",
    "\n",
    "# List of invalid values to remove\n",
    "invalid_countries = ['no', 'unknown', 'none', 'not applicable', 'unknown/at sea', 'unavailable', 'in orbit', 'space', 'atlantic ocean', 'caribbean sea', 'pacific ocean', 'international space station', 'moon', 'mars', 'none', 'not found']\n",
    "\n",
    "# Convert the 'Country' column to lowercase and filter out invalid values\n",
    "ufo_report = ufo_report[~ufo_report['country'].str.lower().isin(invalid_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Country_Code column\n",
    "# Funktion zum Abrufen des ISO 3166-1 Alpha-2 Ländercodes\n",
    "def get_country_code(country_name):\n",
    "    if isinstance(country_name, str):  # Prüfen, ob es eine Zeichenkette ist\n",
    "        country = pycountry.countries.get(name=country_name)\n",
    "        return country.alpha_2 if country else None\n",
    "    return None  # Falls der Wert kein String ist (z. B. NaN)\n",
    "\n",
    "# Beispiel-Datenframe erstellen (falls noch nicht vorhanden)\n",
    "# ufo_report = pd.read_csv(\"deine_datei.csv\")  # Falls Daten aus einer CSV geladen werden\n",
    "\n",
    "# Neue Spalte \"Country_Code\" erstellen\n",
    "ufo_report['country_code'] = ufo_report['country'].apply(lambda x: get_country_code(x) \n",
    "    if isinstance(x, str) and x.lower() not in ['non applicable', 'unknown', 'in orbit', 'at sea'] else None)\n",
    "\n",
    "# Zeilen mit fehlendem \"Country_Code\" entfernen\n",
    "ufo_report = ufo_report.dropna(subset=['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/2021</td>\n",
       "      <td>Felpham/Bognor Regis (UK/England)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/2014</td>\n",
       "      <td>Swindon (UK/England)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/2020</td>\n",
       "      <td>Brocket (Canada)</td>\n",
       "      <td>AB</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/2013</td>\n",
       "      <td>Lincoln (Lincolnshire) (UK/England)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/2014</td>\n",
       "      <td>Port Coquitlam (Canada)</td>\n",
       "      <td>BC</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>01/1958</td>\n",
       "      <td>Birchy Bay (Canada)</td>\n",
       "      <td>NF</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14582</th>\n",
       "      <td>04/1957</td>\n",
       "      <td>Lahore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14583</th>\n",
       "      <td>10/1955</td>\n",
       "      <td>Chester (UK/England)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14584</th>\n",
       "      <td>10/1952</td>\n",
       "      <td>Fukuoka (Japan)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14585</th>\n",
       "      <td>06/1950</td>\n",
       "      <td>Budapest (Hungary)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14586 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                 city    state  country_id\n",
       "0      06/2021    Felpham/Bognor Regis (UK/England)  Unknown          79\n",
       "1      10/2014                 Swindon (UK/England)  Unknown          79\n",
       "2      04/2020                     Brocket (Canada)       AB          39\n",
       "3      08/2013  Lincoln (Lincolnshire) (UK/England)  Unknown          79\n",
       "4      08/2014              Port Coquitlam (Canada)       BC          39\n",
       "...        ...                                  ...      ...         ...\n",
       "14581  01/1958                  Birchy Bay (Canada)       NF          39\n",
       "14582  04/1957                               Lahore  Unknown         172\n",
       "14583  10/1955                 Chester (UK/England)  Unknown          79\n",
       "14584  10/1952                      Fukuoka (Japan)  Unknown         115\n",
       "14585  06/1950                   Budapest (Hungary)  Unknown         101\n",
       "\n",
       "[14586 rows x 4 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge ufo_report with countries_df to get the corresponding country_id\n",
    "ufo_report = ufo_report.merge(countries_df[['handle', 'country_id']], how='left', left_on='country_code', right_on='handle')\n",
    "\n",
    "# Replace the country_code column with the country_id column\n",
    "ufo_report['country_code'] = ufo_report['country_id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "ufo_report.drop(columns=['handle', 'country_id', \"country\"], inplace=True)\n",
    "ufo_report = ufo_report.rename(columns={\"country_code\":\"country_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subscribers Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\subscribers_netflix_2024 (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = subscribers.rename(columns={'estimated_subscribers': 'subscribers'}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ufo_report with countries_df to get the corresponding country_id\n",
    "subscribers = subscribers.merge(countries_df[['handle', 'country_id']], how='left', left_on='country_code', right_on='handle')\n",
    "\n",
    "# Replace the country_code column with the country_id column\n",
    "subscribers['country_code'] = subscribers['country_id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "subscribers.drop(columns=['handle', 'country_id', \"country\"], inplace=True)\n",
    "subscribers = subscribers.rename(columns={\"country_code\":\"country_id\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
