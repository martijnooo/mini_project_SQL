{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycountry\n",
    "from projects.ufo_sightings.mini_project_SQL.setup.helper.country_mapping import country_mapping \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\population_date.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "population[population[\"Country Name\"].str.contains(\"hong\", case=False, na=False)]\n",
    "population[\"Country Name\"] = population[\"Country Name\"].replace({\n",
    "    \"Slovak Republic\": \"Slovakia\",\n",
    "    \"Turkiye\": \"TÃ¼rkiye\",\n",
    "    \"Hong Kong SAR, China\": \"Hong Kong\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all countries\n",
    "countries_short = [country.alpha_2 for country in pycountry.countries]\n",
    "countries_name = [country.name for country in pycountry.countries]\n",
    "\n",
    "countries_df = pd.DataFrame({'handle': countries_short, 'name': countries_name}).reset_index()\n",
    "countries_df = countries_df.rename(columns={\"index\":\"country_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = countries_df.merge(population, how=\"left\", left_on=\"name\", right_on=\"Country Name\")\n",
    "combined.drop([\"Country Name\", \"Country Code\"], axis=1, inplace=True)\n",
    "combined.rename(columns={\"Population\":\"population\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Dataset cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8807 entries, 0 to 8806\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   show_id       8807 non-null   object\n",
      " 1   type          8807 non-null   object\n",
      " 2   title         8807 non-null   object\n",
      " 3   director      6173 non-null   object\n",
      " 4   cast          7982 non-null   object\n",
      " 5   country       7976 non-null   object\n",
      " 6   date_added    8797 non-null   object\n",
      " 7   release_year  8807 non-null   int64 \n",
      " 8   rating        8803 non-null   object\n",
      " 9   duration      8804 non-null   object\n",
      " 10  listed_in     8807 non-null   object\n",
      " 11  description   8807 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 825.8+ KB\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\netflix_titles_anandshaw.csv\")\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
       "       'release_year', 'rating', 'duration', 'listed_in', 'description',\n",
       "       'ufo_theme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows with including the words \"alien\" and \"ufo\" in the title or description? \n",
    "filtered_df = movies[movies['title'].str.contains('alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', case=False, na=False) | \n",
    "                     movies['description'].str.contains('alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', case=False, na=False)]\n",
    "print(len(filtered_df))\n",
    "\n",
    "# create new column that indicates if movie has ufo theme\n",
    "movies['ufo_theme'] = np.where(\n",
    "    movies['description'].str.contains(\n",
    "        'alien|ufo|extraterrestrial|spaceship|spacecraft|cosmic|intergalactic|martian|extraterrestrials|galactic|asteroid|space|starship', \n",
    "        case=False, \n",
    "        na=False\n",
    "    ), \n",
    "    'yes', \n",
    "    'no'\n",
    ")\n",
    "\n",
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['date_added'] = pd.to_datetime(movies['date_added'], errors='coerce')\n",
    "# Drop rows where 'date_added' is NaT due to coercion errors\n",
    "movies = movies.dropna(subset=['date_added'])\n",
    "movies = movies[['date_added', 'ufo_theme', 'release_year', 'type', 'title']]\n",
    "movies['date_added_formatted'] = movies['date_added'].dt.strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFO reports cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo_report  = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\nuforc_reports (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143940 entries, 0 to 143939\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Date_Table  143940 non-null  object\n",
      " 1   Date        143940 non-null  object\n",
      " 2   Posted      143940 non-null  object\n",
      " 3   City        143933 non-null  object\n",
      " 4   State       143895 non-null  object\n",
      " 5   Country     143938 non-null  object\n",
      " 6   Shape       143940 non-null  object\n",
      " 7   Duration    143915 non-null  object\n",
      " 8   Image       143940 non-null  object\n",
      " 9   Link        143940 non-null  object\n",
      " 10  Summary     143940 non-null  object\n",
      " 11  Text        143906 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ufo_report.info()\n",
    "\n",
    "# rename columns to lower case\n",
    "ufo_report.columns = ufo_report.columns.str.lower()\n",
    "\n",
    "# remove columns 'Date', 'Posted', 'Shape', 'Duration', 'Image', 'Link', 'Summary', 'Text' (to avoid confusion about correct date column and other columns)\n",
    "ufo_report = ufo_report.drop(columns=['date','posted', 'shape', 'duration', 'image', 'link', 'summary', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date                city    state  country\n",
      "0                         04/2023            Honolulu       HI      USA\n",
      "1                         04/2023         Bakersfield  Unknown      USA\n",
      "2                         04/2023         Castle Dale  Unknown  Unknown\n",
      "3                         04/2023           Baltimore       MD      USA\n",
      "4                         03/2023             Madison       WI      USA\n",
      "...                           ...                 ...      ...      ...\n",
      "143935                    07/1947             Roswell       NM      USA\n",
      "143936                    06/1947      Corpus Christi       TX      USA\n",
      "143937                    06/1952              Auburn       WA      USA\n",
      "143938  UNSPECIFIED / APPROXIMATE           Troutdale       OR      USA\n",
      "143939                    06/1950  Budapest (Hungary)  Unknown  Hungary\n",
      "\n",
      "[143940 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# rename column date_table\n",
    "ufo_report = ufo_report.rename(columns={'date_table': 'date'})\n",
    "print(ufo_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid rows: 376\n",
      "           date                city    state  country\n",
      "0       04/2023            Honolulu       HI      USA\n",
      "1       04/2023         Bakersfield  Unknown      USA\n",
      "2       04/2023         Castle Dale  Unknown  Unknown\n",
      "3       04/2023           Baltimore       MD      USA\n",
      "4       03/2023             Madison       WI      USA\n",
      "...         ...                 ...      ...      ...\n",
      "143934  07/1954             Oakdale       NY      USA\n",
      "143935  07/1947             Roswell       NM      USA\n",
      "143936  06/1947      Corpus Christi       TX      USA\n",
      "143937  06/1952              Auburn       WA      USA\n",
      "143939  06/1950  Budapest (Hungary)  Unknown  Hungary\n",
      "\n",
      "[143564 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "correct_format = r'^\\d{1,2}/\\d{4}$'\n",
    "\n",
    "# count rows that do not have date format of MM/YYYY in 'Date_Table'\n",
    "invalid_rows_count = ufo_report[~ufo_report['date'].str.match(correct_format, na=False)].shape[0]\n",
    "\n",
    "print(f\"invalid rows: {invalid_rows_count}\")\n",
    "\n",
    "# remove rows with invalid date format \n",
    "ufo_report = ufo_report[ufo_report['date'].str.match(correct_format, na=False)]\n",
    "print(ufo_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'Unknown' 'United Kingdom' 'Canada' 'Turkey' 'India'\n",
      " 'Australia' 'Malta' 'Switzerland' 'France' 'Guam' 'Puerto Rico' 'Ukraine'\n",
      " 'Mexico' 'Ireland' 'Japan' 'Germany' 'Poland' 'New Zealand' 'Pakistan'\n",
      " 'South Africa' 'Papua New Guinea' 'Kenya' 'Thailand' 'Israel' 'Denmark'\n",
      " 'Malaysia' 'Lebanon' 'Argentina' 'Myanmar' 'Cambodia' 'Croatia' 'Brazil'\n",
      " 'North Macedonia' 'Cyprus' 'China' 'Panama' 'Romania' 'In Orbit'\n",
      " 'Trinidad and Tobago' 'Jamaica' 'Luxembourg' 'Italy' 'Bulgaria' 'Iran'\n",
      " 'Spain' 'Portugal' 'Indonesia' 'South Korea' 'Belgium' 'Netherlands'\n",
      " 'Philippines' 'Guatemala' 'Sri Lanka' 'Jordan' 'Afghanistan' 'Finland'\n",
      " 'Taiwan' 'Algeria' 'Venezuela' 'Bahamas'\n",
      " 'South Georgia and the South Sandwich Islands' 'Costa Rica' 'Honduras'\n",
      " 'Lithuania' 'Bahrain' 'Palau' 'Mozambique' 'Dominican Republic' 'Belize'\n",
      " 'Slovenia' 'Bosnia and Herzegovina' 'Colombia' 'Greece' 'Hungary'\n",
      " 'Latvia' 'Sweden' 'Portereco  2 miles of the coast' 'Peru' 'Armenia'\n",
      " 'Mauritius' 'Egypt' 'Nigeria' 'Mars' 'Caribbean Sea' 'Djibouti' 'Norway'\n",
      " 'Fiji' 'Iraq' 'Bangladesh' 'Czechia' 'Serbia' 'Zimbabwe' 'Bolivia'\n",
      " 'Russia' 'Isle of Man' 'Viet Nam' 'Oman' 'Nicaragua' 'Brunei' 'Chile'\n",
      " 'Turks and Caicos Islands' 'United States\\r\\n\\r\\n\\r\\n' 'Grenada' 'Zambia'\n",
      " 'Georgia' 'United States Virgin Islands' 'Austria' 'Dominica' 'Qatar'\n",
      " 'Hong Kong' 'Bermuda' None 'Kosovo' 'Ecuador' 'Russian Federation'\n",
      " 'United Arab Emirates' 'CuraÃ§ao' 'British Virgin Islands' 'Cuba'\n",
      " 'Tunisia' 'Azerbaijan' 'Albania' 'Estonia' 'Botswana' 'Slovakia'\n",
      " 'Morocco' 'Saudi Arabia' 'Kuwait' 'Nepal' 'Maldives' 'Iceland'\n",
      " 'Northern Mariana Islands' 'Barbados' 'Kazakhstan' 'American Samoa'\n",
      " 'Liberia' 'Tanzania' 'No' 'Singapore' 'Mongolia' 'Namibia' 'In orbit'\n",
      " 'South Atlantic/Caribbean (on cruise ship)' 'Atlantic Ocean'\n",
      " 'Antigua and Barbuda' 'none' 'Senegal' 'Martinique'\n",
      " 'Saint Kitts and Nevis' 'Syria' 'Moon' 'In orbit (space)' 'Seychelles'\n",
      " 'Yup' 'Mediterranean Sea' 'Antarctica' 'Paraguay' 'Ghana' 'Yes' 'Aruba'\n",
      " 'Vietnam' 'RÃ©union' 'El Salvador' 'Nauru' 'Angola' 'Gambia'\n",
      " 'Cayman Islands' 'Kyrgyzstan' 'Uruguay' 'In orbit in space' 'Ethiopia'\n",
      " 'Pacific Ocean' 'Grenadine Islands' 'Saint Helena' 'Greenland'\n",
      " 'Gulf of Mexico / Florida straits' 'El Cobre' 'Suriname' 'Indian Ocean'\n",
      " 'mid-Atlantic Ocean' 'Yugoslavia' 'Europe' 'Untied States of America'\n",
      " 'Chad' 'Yemen' 'Sweden/Denmark' 'Persian Gulf' 'Congo'\n",
      " 'Space via nasa tv' 'Uzbekistan' 'France/Antibes' 'U' 'yes' 'Gibraltar'\n",
      " 'Sint Maarten' 'Haiti' 'Saint Lucia' 'Tokyo to Honolulu' 'TÃ¼rkiye'\n",
      " 'Democratic Republic of the Congo' 'Mid-Atlantic Ocean' 'United kingdom'\n",
      " 'Nairobi' 'slovakia' 'Palestine' 'Lesotho' 'East Timor' 'Netherlands The'\n",
      " 'Virgin Islands (U.S.)' 'Monaco' 'Sri lanka' 'Tasmania' 'Gulf of Mexico'\n",
      " 'Republic of Georgia' 'Cameroon' 'Kosova' 'Republic of Korea'\n",
      " 'Colorado springs' 'Federated States of Micronesia' 'SriLanka'\n",
      " 'Czech republic' 'over New Brunswick' 'Lake Ontario'\n",
      " 'Pacific Ocean (in-fight)' 'sri lanka' 'Guinea' nan 'Surinam'\n",
      " 'Myanmar (Burma)' 'Faroe Islands' 'SI' 'Sinai'\n",
      " 'International Space Station' 'Switzerland/UK (in flight)' 'Anguilla'\n",
      " 'UK/Wales' 'Guyana, South America' 'finland' 'Channel Islands'\n",
      " 'Above the pacific ocean' 'Guatamala' 'Puerto Rico usa'\n",
      " 'French Polynesia' 'great britain' 'USA/Canadian Waters' 'Ochorios'\n",
      " 'San Juan and St. Thomas USVI' 'Uganda' 'New Zealand -Taranaki' 'Guyana'\n",
      " 'Malawi' 'Panama Canal Zone' 'Euleuthera' 'Nekoosa' 'North Sea'\n",
      " 'Montenegro' 'Vanuatu' 'Caribbean' 'United States Minor Outlying Islands'\n",
      " 'San Miguel Tecuitlapa, Puebla, Mexico' 'Outer Mongolia' 'Burkina Faso'\n",
      " 'Atlantic Ocean/Puerto Rico' 'Libya' 'Germany (West Germany)'\n",
      " 'St. Helena Island' 'Grand Cayman Island' 'Virgin Islands (US)' 'Tonga'\n",
      " 'St. Martin' 'Tyrrhenian Sea' 'Israel - near Petach Tikva'\n",
      " 'Rhodesia (Now Zimbabwe)' 'Solomon Islands' 'Moldova (Republic of )'\n",
      " 'India (south- east)' 'Somalia' 'Slovakia/Austria' 'Belarus'\n",
      " 'Pacific Ocean (western)' 'South Atlantic Ocean' 'CZECH republic'\n",
      " 'Republic of Palau' 'Dubai' 'Saint Kitts And Nevis' 'france'\n",
      " 'St. Maarten/Netherland Antilles' 'Swaziland' 'Mauritius Island' 'Laos'\n",
      " 'Tuvalu' 'Middle of the Atlantic Ocean' 'lat 2 deg 48 min N  124 deg W'\n",
      " 'Near Earth Orbit' 'Turkmenistan' 'Dominican republic' 'saipan'\n",
      " 'Tunisia-ITALIA,MIDELLSEA' 'Kazakstan' 'Netherland Antilles' 'St. Thomas'\n",
      " 'Cruise ship' 'Fiji Islands' 'Cape Verde Island' 'Germany/France'\n",
      " 'South Pacific' 'USA & Canada' 'South Pacific Ocean' 'Central Viet Nam'\n",
      " 'Russia (USSR)' 'Azores' 'Far East' 'Midway Island' 'mediterranean sea'\n",
      " 'Philippine Sea' 'South Vietnam' 'no' 'unknown/at sea'\n",
      " 'Mediterrainian Sea' 'Orust']\n"
     ]
    }
   ],
   "source": [
    "# based on unique values from country we clean country column and remove invalid values\n",
    "ufo_report[\"country\"] = ufo_report[\"country\"].replace(country_mapping)\n",
    "unique_countries = ufo_report['country'].unique()\n",
    "print(unique_countries)\n",
    "\n",
    "# List of invalid values to remove\n",
    "invalid_countries = ['no', 'unknown', \"Unknown\" 'none', 'not applicable', 'unknown/at sea', 'unavailable', 'in orbit', 'space', 'atlantic ocean', 'caribbean sea', 'pacific ocean', 'international space station', 'moon', 'mars', 'none', 'not found']\n",
    "\n",
    "# Convert the 'Country' column to lowercase and filter out invalid values\n",
    "ufo_report = ufo_report[~ufo_report['country'].str.lower().isin(invalid_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Country_Code column\n",
    "# Funktion zum Abrufen des ISO 3166-1 Alpha-2 LÃ¤ndercodes\n",
    "def get_country_code(country_name):\n",
    "    if isinstance(country_name, str):  # PrÃ¼fen, ob es eine Zeichenkette ist\n",
    "        country = pycountry.countries.get(name=country_name)\n",
    "        return country.alpha_2 if country else None\n",
    "    return None  # Falls der Wert kein String ist (z. B. NaN)\n",
    "\n",
    "# Beispiel-Datenframe erstellen (falls noch nicht vorhanden)\n",
    "# ufo_report = pd.read_csv(\"deine_datei.csv\")  # Falls Daten aus einer CSV geladen werden\n",
    "\n",
    "# Neue Spalte \"Country_Code\" erstellen\n",
    "ufo_report['country_code'] = ufo_report['country'].apply(lambda x: get_country_code(x) \n",
    "    if isinstance(x, str) and x.lower() not in ['non applicable', 'unknown', 'in orbit', 'at sea'] else None)\n",
    "\n",
    "# Zeilen mit fehlendem \"Country_Code\" entfernen\n",
    "ufo_report = ufo_report.dropna(subset=['country_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140400</th>\n",
       "      <td>01/1910</td>\n",
       "      <td>Kirksville (near)</td>\n",
       "      <td>MO</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140426</th>\n",
       "      <td>01/1929</td>\n",
       "      <td>Santa Teresa</td>\n",
       "      <td>NM</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140493</th>\n",
       "      <td>01/1943</td>\n",
       "      <td>Fiji Islands (S. Pacific Ocean)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>FJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140521</th>\n",
       "      <td>01/1944</td>\n",
       "      <td>Wilderness (near western MD)</td>\n",
       "      <td>WV</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140490</th>\n",
       "      <td>01/1944</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49232</th>\n",
       "      <td>12/2022</td>\n",
       "      <td>Chokoloskee</td>\n",
       "      <td>FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105562</th>\n",
       "      <td>12/2022</td>\n",
       "      <td>Lompoc</td>\n",
       "      <td>CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76494</th>\n",
       "      <td>12/2022</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134822</th>\n",
       "      <td>12/2022</td>\n",
       "      <td>Sarasota</td>\n",
       "      <td>FL</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53741</th>\n",
       "      <td>12/2022</td>\n",
       "      <td>University Place/ Tacoma</td>\n",
       "      <td>WA</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142677 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                             city    state        country  \\\n",
       "140400  01/1910                Kirksville (near)       MO  United States   \n",
       "140426  01/1929                     Santa Teresa       NM  United States   \n",
       "140493  01/1943  Fiji Islands (S. Pacific Ocean)  Unknown           Fiji   \n",
       "140521  01/1944     Wilderness (near western MD)       WV  United States   \n",
       "140490  01/1944                        San Diego       CA  United States   \n",
       "...         ...                              ...      ...            ...   \n",
       "49232   12/2022                      Chokoloskee       FL  United States   \n",
       "105562  12/2022                           Lompoc       CA  United States   \n",
       "76494   12/2022                           Denver       CO  United States   \n",
       "134822  12/2022                         Sarasota       FL  United States   \n",
       "53741   12/2022         University Place/ Tacoma       WA  United States   \n",
       "\n",
       "       country_code  \n",
       "140400           US  \n",
       "140426           US  \n",
       "140493           FJ  \n",
       "140521           US  \n",
       "140490           US  \n",
       "...             ...  \n",
       "49232            US  \n",
       "105562           US  \n",
       "76494            US  \n",
       "134822           US  \n",
       "53741            US  \n",
       "\n",
       "[142677 rows x 5 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_report.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ufo_report with countries_df to get the corresponding country_id\n",
    "ufo_report = ufo_report.merge(countries_df[['handle', 'country_id']], how='left', left_on='country_code', right_on='handle')\n",
    "\n",
    "# Replace the country_code column with the country_id column\n",
    "ufo_report['country_code'] = ufo_report['country_id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "ufo_report.drop(columns=['handle', 'country_id', \"country\"], inplace=True)\n",
    "ufo_report = ufo_report.rename(columns={\"country_code\":\"country_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subscribers Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = pd.read_csv(r\"C:\\Users\\Martijn\\Downloads\\subscribers_netflix_2024 (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscribers = subscribers.rename(columns={'estimated_subscribers': 'subscribers'}).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ufo_report with countries_df to get the corresponding country_id\n",
    "subscribers = subscribers.merge(countries_df[['handle', 'country_id']], how='left', left_on='country_code', right_on='handle')\n",
    "\n",
    "# Replace the country_code column with the country_id column\n",
    "subscribers['country_code'] = subscribers['country_id']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "subscribers.drop(columns=['handle', 'country_id', \"country\"], inplace=True)\n",
    "subscribers = subscribers.rename(columns={\"country_code\":\"country_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique entries from both columns\n",
    "unique_dates_ufo = ufo_report[\"date\"].unique()\n",
    "unique_dates_movies = movies[\"date_added_formatted\"].unique()\n",
    "\n",
    "# Combine and get all unique entries\n",
    "all_unique_dates = pd.unique(np.concatenate((unique_dates_ufo, unique_dates_movies)))\n",
    "# Create a mapping of dates to their indices in all_unique_dates\n",
    "date_to_index = {date: idx for idx, date in enumerate(all_unique_dates)}\n",
    "\n",
    "# Replace dates in ufo_report[\"date\"] with their corresponding indices\n",
    "ufo_report[\"date_index\"] = ufo_report[\"date\"].map(date_to_index)\n",
    "\n",
    "# Replace dates in movies[\"date_added_formatted\"] with their corresponding indices\n",
    "movies[\"date_index\"] = movies[\"date_added_formatted\"].map(date_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139569    01/1910\n",
       "139588    01/1929\n",
       "139621    01/1943\n",
       "139645    01/1944\n",
       "139618    01/1944\n",
       "           ...   \n",
       "49014     12/2022\n",
       "104976    12/2022\n",
       "76109     12/2022\n",
       "134027    12/2022\n",
       "53492     12/2022\n",
       "Name: date, Length: 142677, dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_report[\"date\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the 'date' column and filter rows with year >= 1900\n",
    "ufo_report = ufo_report[ufo_report['date'].str.extract(r'(\\d{4})')[0].astype(int) >= 1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mini_project_SQL/\n",
      "    README.md\n",
      "    data_cleaning.ipynb\n",
      "    database_init.ipynb\n",
      "    .git/\n",
      "        description\n",
      "        packed-refs\n",
      "        HEAD\n",
      "        config\n",
      "        index\n",
      "        COMMIT_EDITMSG\n",
      "        hooks/\n",
      "            applypatch-msg.sample\n",
      "            commit-msg.sample\n",
      "            fsmonitor-watchman.sample\n",
      "            post-update.sample\n",
      "            pre-applypatch.sample\n",
      "            pre-commit.sample\n",
      "            pre-merge-commit.sample\n",
      "            pre-push.sample\n",
      "            pre-rebase.sample\n",
      "            pre-receive.sample\n",
      "            prepare-commit-msg.sample\n",
      "            push-to-checkout.sample\n",
      "            sendemail-validate.sample\n",
      "            update.sample\n",
      "        info/\n",
      "            exclude\n",
      "        objects/\n",
      "            pack/\n",
      "                pack-43996b0c891f029a4389a5080290faaf78d5831c.pack\n",
      "                pack-43996b0c891f029a4389a5080290faaf78d5831c.idx\n",
      "                pack-43996b0c891f029a4389a5080290faaf78d5831c.rev\n",
      "            info/\n",
      "            1a/\n",
      "                eca9a105fcd5458ce5388855a36aba575f5b33\n",
      "            47/\n",
      "                d4037bff5bd80a0c967e92c165115308a25eb8\n",
      "            0e/\n",
      "                43c609fd5e96d170ffa8ee9856435386918324\n",
      "            af/\n",
      "                2f75cccece74ac72968395c1efb49b0510783d\n",
      "            3a/\n",
      "                a9c02103517338a1c3a750710a32f1e36b4f6f\n",
      "            92/\n",
      "                508eb46a8ba9c10c39332901439b2b468e0772\n",
      "            44/\n",
      "                112ac517021feab6092ae25e55c3140299774e\n",
      "            bf/\n",
      "                f4f79fdd8b08b5cefc53163126aeb053469405\n",
      "            68/\n",
      "                ca00f2ee2db80350289efb7b0c0bad3956c288\n",
      "            a9/\n",
      "                403c90de06fc0a38a4d2a39ba4a389f4fb8196\n",
      "            33/\n",
      "                e60171fd86cf4f7311e988aba8b43dc553efe3\n",
      "            57/\n",
      "                caa46ba0581d381a8c5bf5a83aef2e47048d4b\n",
      "            5b/\n",
      "                92b3ebcdec2067967b080de8c221fc5fd9b276\n",
      "            d2/\n",
      "                30572bee1c3fb3e7ba882f3ca9951c37495d3f\n",
      "            c2/\n",
      "                edaf1e17db5962c0da658cd837220b0e00584c\n",
      "            c1/\n",
      "                a3cece4f72b8e1da0e1f98419812d026f3a760\n",
      "            d8/\n",
      "                de9002f6e6d956b51dbec8df957d953a985484\n",
      "            ed/\n",
      "                32a0d2eada8cb901b1b34ca3bd9c832ce2b1b2\n",
      "            2c/\n",
      "                d876d5ebdc5e41e3d1834ccaca8929e37c5f9b\n",
      "            fc/\n",
      "                eeff0c199c48704887e31d778b6ada2a338203\n",
      "            a8/\n",
      "                217604931d7252ae3d79294e3f38cd019a9826\n",
      "            bb/\n",
      "                0acd47838bcc65a50dbb46f39588898cc916cb\n",
      "            c0/\n",
      "                768f0f444729525a322e831f36e934a2898423\n",
      "                9388c4240f93a1c5d9c0b77fda7e27016f3b9a\n",
      "            1e/\n",
      "                33ac4cde7f9d31c7addb3336b420b093c31a6a\n",
      "            3f/\n",
      "                69da6456984327910db0b2636d3454d2bddd10\n",
      "        refs/\n",
      "            heads/\n",
      "                main\n",
      "                MB\n",
      "            tags/\n",
      "            remotes/\n",
      "                origin/\n",
      "                    HEAD\n",
      "                fork/\n",
      "                    MB\n",
      "        logs/\n",
      "            HEAD\n",
      "            refs/\n",
      "                remotes/\n",
      "                    origin/\n",
      "                        HEAD\n",
      "                    fork/\n",
      "                        MB\n",
      "                heads/\n",
      "                    main\n",
      "                    MB\n",
      "    __pycache__/\n",
      "        data_cleaning_functions.cpython-38.pyc\n",
      "        sql_engine.cpython-38.pyc\n",
      "        country_mapping.cpython-38.pyc\n",
      "    analysis/\n",
      "        analysis.ipynb\n",
      "    setup/\n",
      "        data_cleaning_functions.py\n",
      "        populate_database.py\n",
      "        EER.mwb\n",
      "        database_init.py\n",
      "        helper/\n",
      "            sql_engine.py\n",
      "            country_mapping.py\n",
      "            __pycache__/\n",
      "                sql_engine.cpython-38.pyc\n",
      "                country_mapping.cpython-38.pyc\n",
      "        __pycache__/\n",
      "            data_cleaning_functions.cpython-38.pyc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_folder_structure(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        level = root.replace(path, '').count(os.sep)  # count the folder depth\n",
    "        indent = ' ' * 4 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for file in files:\n",
    "            print(f\"{subindent}{file}\")\n",
    "\n",
    "get_folder_structure(r\"G:\\My Drive\\Ironhack\\projects\\ufo_sightings\\mini_project_SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139542</th>\n",
       "      <td>06/1400</td>\n",
       "      <td>Myers Spring Canyon</td>\n",
       "      <td>TX</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139543</th>\n",
       "      <td>02/1721</td>\n",
       "      <td>Crescent City</td>\n",
       "      <td>CA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139544</th>\n",
       "      <td>03/1861</td>\n",
       "      <td>New York City (Manhattan)</td>\n",
       "      <td>NY</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139545</th>\n",
       "      <td>09/1639</td>\n",
       "      <td>Muddy River (Brookline)(Boston)</td>\n",
       "      <td>MA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139546</th>\n",
       "      <td>05/1864</td>\n",
       "      <td>Cave Spring</td>\n",
       "      <td>GA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139547</th>\n",
       "      <td>04/1561</td>\n",
       "      <td>Nurnburg (Germany)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139548</th>\n",
       "      <td>04/1561</td>\n",
       "      <td>Nuremberg (Germany)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139549</th>\n",
       "      <td>06/1898</td>\n",
       "      <td>Unspecified location</td>\n",
       "      <td>OK</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139552</th>\n",
       "      <td>12/1762</td>\n",
       "      <td>Lulworth, Dorsetshire (near) (UK/England)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139553</th>\n",
       "      <td>08/1860</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>NC</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139554</th>\n",
       "      <td>06/1871</td>\n",
       "      <td>Yellowstone National Park</td>\n",
       "      <td>WY</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139556</th>\n",
       "      <td>06/1790</td>\n",
       "      <td>Carlisle</td>\n",
       "      <td>NY</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139560</th>\n",
       "      <td>06/1896</td>\n",
       "      <td>Melbourne (VIC, Australia)</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139561</th>\n",
       "      <td>04/1800</td>\n",
       "      <td>Baton Rouge</td>\n",
       "      <td>LA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139562</th>\n",
       "      <td>06/1865</td>\n",
       "      <td>Cadotte Pass</td>\n",
       "      <td>MT</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139563</th>\n",
       "      <td>06/1899</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>MO</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139564</th>\n",
       "      <td>05/1864</td>\n",
       "      <td>Cave Springs</td>\n",
       "      <td>GA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139585</th>\n",
       "      <td>04/1897</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>TX</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139586</th>\n",
       "      <td>12/1880</td>\n",
       "      <td>Bellingham</td>\n",
       "      <td>WA</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139587</th>\n",
       "      <td>04/1897</td>\n",
       "      <td>Howard/Artesian</td>\n",
       "      <td>SD</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                       city    state  \\\n",
       "139542  06/1400                        Myers Spring Canyon       TX   \n",
       "139543  02/1721                              Crescent City       CA   \n",
       "139544  03/1861                  New York City (Manhattan)       NY   \n",
       "139545  09/1639            Muddy River (Brookline)(Boston)       MA   \n",
       "139546  05/1864                                Cave Spring       GA   \n",
       "139547  04/1561                         Nurnburg (Germany)  Unknown   \n",
       "139548  04/1561                        Nuremberg (Germany)  Unknown   \n",
       "139549  06/1898                       Unspecified location       OK   \n",
       "139552  12/1762  Lulworth, Dorsetshire (near) (UK/England)  Unknown   \n",
       "139553  08/1860                                   Cherokee       NC   \n",
       "139554  06/1871                  Yellowstone National Park       WY   \n",
       "139556  06/1790                                   Carlisle       NY   \n",
       "139560  06/1896                 Melbourne (VIC, Australia)  Unknown   \n",
       "139561  04/1800                                Baton Rouge       LA   \n",
       "139562  06/1865                               Cadotte Pass       MT   \n",
       "139563  06/1899                                 Carrollton       MO   \n",
       "139564  05/1864                               Cave Springs       GA   \n",
       "139585  04/1897                                     Aurora       TX   \n",
       "139586  12/1880                                 Bellingham       WA   \n",
       "139587  04/1897                            Howard/Artesian       SD   \n",
       "\n",
       "        country_id  \n",
       "139542         234  \n",
       "139543         234  \n",
       "139544         234  \n",
       "139545         234  \n",
       "139546         234  \n",
       "139547          59  \n",
       "139548          59  \n",
       "139549         234  \n",
       "139552          79  \n",
       "139553         234  \n",
       "139554         234  \n",
       "139556         234  \n",
       "139560          14  \n",
       "139561         234  \n",
       "139562         234  \n",
       "139563         234  \n",
       "139564         234  \n",
       "139585         234  \n",
       "139586         234  \n",
       "139587         234  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_report[ufo_report['date'].str.extract(r'(\\d{4})')[0].astype(int) <= 1900]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
